**String Interpolation Plan**

- `src/frontend/lexer.zig:148` currently treats a double-quoted literal as one `string_literal` token whose contents are opaque to the parser, so `${…}` never reaches the expression grammar. To support arbitrary Runic expressions inside interpolations, add explicit string-template tokens to `token.Tag` (`string_start`, `string_end`, `string_text`, `string_interp_start`, `string_interp_end`). Update `Lexer` so `next()` first checks whether there is an active string context. Enter that context when seeing `"`, emit a `string_start`, and scan forward until the next `"`, watching for `${`. Each time `${` appears, flush the preceding slice as `string_text`, emit `string_interp_start`, mark that we are inside an interpolation, and let the normal token machinery run for the embedded expression. Track `()`/`[]`/`{}` depth (e.g. counters on a small stack) so a `}` only closes the interpolation when every counter is zero; otherwise emit the ordinary `.r_brace`. When the interpolation-ending `}` is found, emit a `string_interp_end` token and resume text scanning inside the outer string. When the closing quote is reached, flush the trailing text (if any) as `string_text`, emit `string_end`, and pop the string context. This gives the parser ordinary tokens for the embedded expression while guarding the boundary with two dedicated tokens.

- `src/frontend/parser.zig:606` needs to switch from slicing `tok.lexeme` to consuming the streaming tokens. Update `parsePrimaryExpression()`/`parsePipelineStage()` so they look for `.string_start` instead of `.string_literal`. Rewrite `parseStringLiteral` to drive a small loop: after consuming the `string_start`, repeatedly accept `string_text` tokens (appending `.Segment.text` slices) and, when a `string_interp_start` is seen, call the existing `parseExpression()` to parse the embedded Runic expression. After the expression finishes, require `.string_interp_end` and append the returned AST node as `.Segment.interpolation`. Break when `.string_end` arrives. Because interpolation expressions reuse the full parser, all constructs (`if`, pipelines, arrays, nested strings, etc.) now work. `parseStringLiteralWithoutInterp()` should be adjusted to either forbid interpolations (error if a `string_interp_start` arrives) or reuse `parseStringLiteral` and assert that every segment is text.

- Any parser routine that currently treats `.r_paren`, `.comma`, `.newline`, etc. as stage terminators (e.g. `parsePipelineStage` around `src/frontend/parser.zig:162`) must add `.string_interp_end` to their “stop” sets so an embedded expression can finish cleanly before the caller consumes the sentinel. This sentinel should never be handed to general expression parsing; the interpolation loop retains it and consumes it immediately after `parseExpression()` returns.

- Update the lexer/unit tests to cover cases like `echo "hello${asdf}"`, nested expressions (`"${if cond { foo } else { bar }}"`), and escaped delimiters. Parser tests in `src/frontend/parser_tests.zig` should assert that the resulting `ast.StringLiteral` contains alternating `text`/`interpolation` segments with spans pointing back to the source.

This change confines all work to the lexer and parser, reuses the existing expression grammar wholesale, and guarantees that `${…}` can hold any valid Runic expression while keeping the AST format (`ast.zig:151`) unchanged. Next steps would be to implement the lexer context stack, adapt the parser helpers, and extend the fixtures/tests mentioned above.
